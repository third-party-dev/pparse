# automatically generated by the FlatBuffers compiler, do not modify

# namespace: MNN

import flatbuffers
from flatbuffers.compat import import_numpy
np = import_numpy()

class QuantizedBiasAdd(object):
    __slots__ = ['_tab']

    @classmethod
    def GetRootAs(cls, buf, offset=0):
        n = flatbuffers.encode.Get(flatbuffers.packer.uoffset, buf, offset)
        x = QuantizedBiasAdd()
        x.Init(buf, n + offset)
        return x

    @classmethod
    def GetRootAsQuantizedBiasAdd(cls, buf, offset=0):
        """This method is deprecated. Please switch to GetRootAs."""
        return cls.GetRootAs(buf, offset)
    # QuantizedBiasAdd
    def Init(self, buf, pos):
        self._tab = flatbuffers.table.Table(buf, pos)

    # QuantizedBiasAdd
    def Bias(self, j):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))
        if o != 0:
            a = self._tab.Vector(o)
            return self._tab.Get(flatbuffers.number_types.Int32Flags, a + flatbuffers.number_types.UOffsetTFlags.py_type(j * 4))
        return 0

    # QuantizedBiasAdd
    def BiasAsNumpy(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))
        if o != 0:
            return self._tab.GetVectorAsNumpy(flatbuffers.number_types.Int32Flags, o)
        return 0

    # QuantizedBiasAdd
    def BiasLength(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))
        if o != 0:
            return self._tab.VectorLen(o)
        return 0

    # QuantizedBiasAdd
    def BiasIsNone(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(4))
        return o == 0

    # QuantizedBiasAdd
    def InputType(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(6))
        if o != 0:
            return self._tab.Get(flatbuffers.number_types.Int32Flags, o + self._tab.Pos)
        return 0

    # QuantizedBiasAdd
    def Max(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(8))
        if o != 0:
            return self._tab.Get(flatbuffers.number_types.Int32Flags, o + self._tab.Pos)
        return 0

    # QuantizedBiasAdd
    def Min(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(10))
        if o != 0:
            return self._tab.Get(flatbuffers.number_types.Int32Flags, o + self._tab.Pos)
        return 0

    # QuantizedBiasAdd
    def OutputType(self):
        o = flatbuffers.number_types.UOffsetTFlags.py_type(self._tab.Offset(12))
        if o != 0:
            return self._tab.Get(flatbuffers.number_types.Int32Flags, o + self._tab.Pos)
        return 0

def QuantizedBiasAddStart(builder):
    builder.StartObject(5)

def Start(builder):
    QuantizedBiasAddStart(builder)

def QuantizedBiasAddAddBias(builder, bias):
    builder.PrependUOffsetTRelativeSlot(0, flatbuffers.number_types.UOffsetTFlags.py_type(bias), 0)

def AddBias(builder, bias):
    QuantizedBiasAddAddBias(builder, bias)

def QuantizedBiasAddStartBiasVector(builder, numElems):
    return builder.StartVector(4, numElems, 4)

def StartBiasVector(builder, numElems: int) -> int:
    return QuantizedBiasAddStartBiasVector(builder, numElems)

def QuantizedBiasAddAddInputType(builder, inputType):
    builder.PrependInt32Slot(1, inputType, 0)

def AddInputType(builder, inputType):
    QuantizedBiasAddAddInputType(builder, inputType)

def QuantizedBiasAddAddMax(builder, max):
    builder.PrependInt32Slot(2, max, 0)

def AddMax(builder, max):
    QuantizedBiasAddAddMax(builder, max)

def QuantizedBiasAddAddMin(builder, min):
    builder.PrependInt32Slot(3, min, 0)

def AddMin(builder, min):
    QuantizedBiasAddAddMin(builder, min)

def QuantizedBiasAddAddOutputType(builder, outputType):
    builder.PrependInt32Slot(4, outputType, 0)

def AddOutputType(builder, outputType):
    QuantizedBiasAddAddOutputType(builder, outputType)

def QuantizedBiasAddEnd(builder):
    return builder.EndObject()

def End(builder):
    return QuantizedBiasAddEnd(builder)
